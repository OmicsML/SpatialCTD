{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"QwKFm-xUxJw7","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d01f40a1-4c17-43fe-a996-997ff3f462eb","executionInfo":{"status":"ok","timestamp":1679526127734,"user_tz":420,"elapsed":24695,"user":{"displayName":"jiayuan ding","userId":"00368278201421210170"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print(\"NO\")\n","else:\n","  print(gpu_info)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WSgw8q1bjqsc","executionInfo":{"status":"ok","timestamp":1679526322420,"user_tz":420,"elapsed":1324,"user":{"displayName":"jiayuan ding","userId":"00368278201421210170"}},"outputId":"69624bf9-6d0a-48cf-9326-45bb79259cf0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Mar 22 23:05:21 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   42C    P0    25W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VzUmZryBZS4N"},"outputs":[],"source":["!cp /content/drive/MyDrive/CosMx_benchmark_pro/mydata.py ./mydata.py"]},{"cell_type":"code","source":["!pip install ipdb"],"metadata":{"id":"kTuURbGRr889"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Add this in a Google Colab cell to install the correct version of Pytorch Geometric.\n","import torch\n","\n","def format_pytorch_version(version):\n","  return version.split('+')[0]\n","\n","TORCH_version = torch.__version__\n","TORCH = format_pytorch_version(TORCH_version)\n","\n","def format_cuda_version(version):\n","  return 'cu' + version.replace('.', '')\n","\n","CUDA_version = torch.version.cuda\n","CUDA = format_cuda_version(CUDA_version)\n","\n","!pip install torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n","!pip install torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n","!pip install torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n","!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n","!pip install torch-geometric "],"metadata":{"id":"kjigXpBjboUu","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e8ee17ce-a2e1-4094-aa5d-8f5c2d65a7d0","executionInfo":{"status":"ok","timestamp":1679476637223,"user_tz":420,"elapsed":27139,"user":{"displayName":"jiayuan ding","userId":"00368278201421210170"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://pytorch-geometric.com/whl/torch-1.13.1+cu116.html\n","Collecting torch-scatter\n","  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_scatter-2.1.1%2Bpt113cu116-cp39-cp39-linux_x86_64.whl (9.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torch-scatter\n","Successfully installed torch-scatter-2.1.1+pt113cu116\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://pytorch-geometric.com/whl/torch-1.13.1+cu116.html\n","Collecting torch-sparse\n","  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_sparse-0.6.17%2Bpt113cu116-cp39-cp39-linux_x86_64.whl (4.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from torch-sparse) (1.10.1)\n","Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.9/dist-packages (from scipy->torch-sparse) (1.22.4)\n","Installing collected packages: torch-sparse\n","Successfully installed torch-sparse-0.6.17+pt113cu116\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://pytorch-geometric.com/whl/torch-1.13.1+cu116.html\n","Collecting torch-cluster\n","  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_cluster-1.6.1%2Bpt113cu116-cp39-cp39-linux_x86_64.whl (3.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from torch-cluster) (1.10.1)\n","Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.9/dist-packages (from scipy->torch-cluster) (1.22.4)\n","Installing collected packages: torch-cluster\n","Successfully installed torch-cluster-1.6.1+pt113cu116\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://pytorch-geometric.com/whl/torch-1.13.1+cu116.html\n","Collecting torch-spline-conv\n","  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_spline_conv-1.2.2%2Bpt113cu116-cp39-cp39-linux_x86_64.whl (868 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.4/868.4 KB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torch-spline-conv\n","Successfully installed torch-spline-conv-1.2.2+pt113cu116\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torch-geometric\n","  Downloading torch_geometric-2.2.0.tar.gz (564 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m565.0/565.0 KB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (4.65.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (1.22.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (1.10.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (3.1.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (2.27.1)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (3.0.9)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (1.2.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (5.9.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch-geometric) (2.1.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torch-geometric) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torch-geometric) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torch-geometric) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torch-geometric) (2.0.12)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->torch-geometric) (1.1.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n","Building wheels for collected packages: torch-geometric\n","  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torch-geometric: filename=torch_geometric-2.2.0-py3-none-any.whl size=773302 sha256=9d6306c56cdc46adebd3254fdce656c9c8712d0bfd3216d61dd9375ce888b0e5\n","  Stored in directory: /root/.cache/pip/wheels/31/b2/8c/9b4bb72a4384eabd1ffeab2b7ead692c9165e35711f8a9dc72\n","Successfully built torch-geometric\n","Installing collected packages: torch-geometric\n","Successfully installed torch-geometric-2.2.0\n"]}]},{"cell_type":"code","source":["import mydata\n","import matplotlib.pyplot as plt\n","import torch_geometric as pyg\n","import torch.nn as nn\n","import torch \n","from torch_geometric.nn import GCNConv, GATConv\n","import torch.nn.functional as F\n","from collections import defaultdict\n","import numpy as np\n","from torch_geometric.data import data as D \n","from tqdm.notebook import tqdm\n","import os \n","import pandas as pd"],"metadata":{"id":"Mw3RF0oyboXP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","class SingletonMeta(type):\n","    __instance = None\n","    def __call__(cls,*args,**kwargs):\n","        if not cls.__instance:\n","            cls.__instance = type.__call__(cls,*args,**kwargs)\n","        return cls.__instance\n","\n","class HugeLog():\n","\n","  def __init__(self,fpath=\"log.md\"):\n","\n","    self.f = open(fpath, 'w')\n","    self.content = defaultdict(list)\n","\n","  def write(self,content):\n","    if type(content) != str:\n","      self.f.write(str(content)+\"\\n\")\n","    else:\n","      self.f.write(content+\"\\n\")\n","    self.f.flush()\n","\n","  def appendImage(self, key, img):\n","    self.content[key].append(img)\n","\n","  def prefixWrite(self, content, prefix=\"[info]  \"):\n","\n","    if type(content) != str:\n","      self.write(prefix + str(content))\n","    else:\n","      self.write(prefix + content)\n","\n","\n","  def info(self,content):\n","\n","    self.prefixWrite(content, prefix=\"[info]. \")\n","\n","  def error(self, content):\n","    self.prefixWrite(content, prefix=\"[Error]. \")\n","    \n","\n","  def other(self,fun,content):\n","    self.write(fun(content))\n","    "],"metadata":{"id":"8q6VYDyRdwe5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","def preprocess_X(X,epsilon=0.00001):\n","    \n","    mean = X.mean()\n","    var  = X.var()\n","    X = (X - mean) / (var + epsilon)\n","    return X\n","\n","\n","def preprocess_Y(Y, weight_list=None):\n","  if weight_list:\n","    Y = Y / np.array(weight_list)\n","  else:\n","    weight_list = [100] + [50] * 17\n","    Y = Y / weight_list\n","  return Y\n","\n","\n","def preprocess_Y_Propobability_softmax(Y):\n","  \n","  temp = Y\n","  temp = np.exp(temp)\n","  temp = (temp.T / temp.sum(axis=-1)).T\n","  return temp\n","\n","\n","def preprocess_Y_Propobability(Y, theta=0.000001):\n","  \n","  temp = Y\n","  temp = (temp.T / (temp.sum(axis=-1) + theta)).T\n","  return temp"],"metadata":{"id":"JC9l0Kp6en5D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def pyg_data_maker(x,y,edge_index, edge_attr, train_mask, val_mask, test_mask,\n","                   x_preprocess = True, ):\n","    \n","    data = D.Data()\n","\n","    if x_preprocess:\n","      x = preprocess_X(x)\n","\n","    y = preprocess_Y_Propobability(y)\n","\n","    x = torch.tensor(x,dtype=torch.float)\n","    y = torch.tensor(y,dtype=torch.float)\n","    edge_index = torch.tensor(edge_index.T,dtype=torch.long)\n","    edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n","\n","    data.x, data.y, data.edge_index, data.edge_attr, data.train_mask, data.val_mask, data.test_mask =  x,y,edge_index, edge_attr, train_mask, val_mask, test_mask\n","    return data"],"metadata":{"id":"gwn8aQJqA4ci"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def fake_graph_generate(nodes, nodes_shape):\n","  \n","  X = np.random.rand(nodes, nodes_shape)\n","  adj, adj_weight = mydata.get_adj(X,topk=5)\n","  return X, adj, adj_weight"],"metadata":{"id":"Q2LN4cEd658E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# model\n","\n","\n","class GCN(nn.Module):\n","    def __init__(self, nfeat=980, nhid=256, gnn_out=64, mlp_hidden=36, nout=18, dropout=0.1):\n","        super(GCN, self).__init__()\n","\n","        self.gc1 = GCNConv(nfeat, nhid)\n","        self.gc2 = GCNConv(nhid, gnn_out)\n","        \n","    def reset_parameters(self):\n","        self.gc1.reset_parameters()\n","        self.gc2.reset_parameters()\n","        # self.mlp.reset_parameters()\n","        \n","    def forward(self, data):\n","        x =  data.x\n","        adj = data.edge_index\n","        weight = data.edge_attr\n","        x = F.leaky_relu(self.gc1(x, adj, weight))\n","        x = self.gc2(x, adj, weight)\n","        return x\n"],"metadata":{"id":"MNukxfqZboZy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","def saveResult(prefix):\n","  if os.path.isdir(prefix):\n","    pass\n","  else:\n","    os.mkdir(prefix)\n","\n","def savefig(prefix, content=['train','test','val','test-jsd','test-mse',\n","                             'test-mae','val-jsd','val-mse','val-mae',\n","                             \"train-mae\",'train-jsd','train-mse']):\n","  for item in content:\n","    fig = plt.figure()\n","    plt.plot(total_loss_collect[item])\n","    plt.title(prefix+\"/\"+item)\n","    plt.savefig(prefix+\"/\"+item+\".png\")\n","\n","\n","def logrecord(prefix=None):\n","\n","  content = ['test-jsd','test-mae','test-mse','test-pcc',\n","            'val-jsd','val-mae', 'val-mse', 'val-pcc',\n","            'train-jsd', 'train-mae','train-mse', 'train-pcc']\n","            \n","  for item in content:\n","    mylog.info(\"min \" + item + \" : \" + str(min(total_loss_collect[item][:-2])))\n","    mylog.info(\"select\" + item + \" : \" + str(total_loss_collect[item][-1]))\n","\n","\n","def outputSave(prefix=None, data=None):\n","  columns = \"tumor\tfibroblast\tmacrophage\tT CD4 memory\tT CD8 memory\tplasmablast\tB-cell\tmast\tTreg\tendothelial\tpDC\tT CD4 naive\tneutrophil\tT CD8 naive\tNK\tmonocyte\tepithelial\tmDC\".split(\"\t\")\n","  data = F.softmax(model(data),dim=1).detach().cpu().numpy()\n","\n","  columns = columns[-1 * data.shape[-1]:]\n","  split_idx = [0,800,1600, len(data)]\n","  for idx in range(len(split_idx)-1):\n","    df = pd.DataFrame(data[split_idx[idx] : split_idx[idx+1]], columns=columns)\n","    df.to_csv(prefix+\"-predict-{}.csv\".format(idx))"],"metadata":{"id":"1aKcDYZULt35"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","def pcc(p, q):\n","    p_mean = torch.mean(p)\n","    q_mean = torch.mean(q)\n","    p_centered = p - p_mean\n","    q_centered = q - q_mean\n","    numerator = torch.sum(p_centered * q_centered)\n","    denominator = torch.sqrt(torch.sum(p_centered ** 2)) * torch.sqrt(torch.sum(q_centered ** 2))\n","    pearson_coef = numerator / denominator\n","    return torch.nan_to_num(pearson_coef)\n","\n","def pcc(p, q):\n","    p_mean = torch.mean(p)\n","    q_mean = torch.mean(q)\n","    p_centered = p - p_mean\n","    q_centered = q - q_mean\n","    numerator = torch.sum(p_centered * q_centered)\n","    denominator = torch.sqrt(torch.sum(p_centered ** 2)) * torch.sqrt(torch.sum(q_centered ** 2))\n","    pearson_coef = numerator / denominator\n","    return torch.nan_to_num(pearson_coef)\n","    \n","def jsd(p_output, q_output):\n","  \"\"\"\n","  Function that measures JS divergence between target and output logits:\n","  \"\"\"\n","  KLDivLoss = nn.KLDivLoss(reduction='batchmean')\n","  log_mean_output = ((p_output + q_output )/2).log()\n","  jsd_result = (KLDivLoss(log_mean_output, p_output) + KLDivLoss(log_mean_output, q_output))/2\n","  return torch.nan_to_num(jsd_result)\n","\n","\n","def mse(p, q):\n","  return (p - q).pow(2).mean()\n","\n","def mae(p, q):\n","  return (p - q).abs().mean() \n","\n","score_fns = [jsd, mse, mae, pcc]\n","\n","# score_fns = [mse, mae]\n"],"metadata":{"id":"SczeGALekSMN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def score_fn(input_, target, mask, softmax=True, prefix='test'):\n","  \n","  p = input_[mask]\n","\n","  if softmax:\n","    p = F.softmax(p, dim=1)\n","\n","  q = target[mask]\n","\n","  # print(\"p:\", p)\n","  # print(\"q:\", q)\n","\n","  # import ipdb\n","  # ipdb.set_trace()\n","\n","  for fn in score_fns:\n","    total_loss_collect[prefix + \"-\" +fn.__name__].append(fn(p, q).item())\n","  return torch.tensor(0)\n","\n","\n","def loss_fn(input_, target, mask):\n","  # input_logit = F.softmax(input_[mask],dim=1)\n","  # target_logit= F.softmax(target[mask],dim=1)\n","  input_logit = input_[mask]\n","  target_logit = target[mask]\n","  loss = F.cross_entropy(input_logit, target_logit)\n","  return loss \n","\n","\n","def test_with_masked_type(test_type=[0,1,2,3]):\n","  gnn_out= len(test_type)\n","  model = GCN(980, gnn_out=gnn_out , nout=len(test_type))\n","  # print(model)\n","  model = fit_mask(data, model, 2000, lr=lr, weight_decay=weight_decay, test_type=test_type)\n","  return model\n","\n","def fit_mask(data, model, epoches, lr=0.0001, weight_decay=0.99, test_type=[0,1,2]):\n","  \n","  if torch.cuda.is_available():\n","    model = model.cuda()\n","    data = data.cuda()\n","    \n","  opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n","  # print(\"learning parameters: lr\",lr)\n","  # train \n","  for epoch in tqdm(range(epoches)):\n","    train_mask_fn(data, model, opt, test_type)\n","    inference(data, model, test_type, prefix='val')\n","    inference(data, model, test_type, prefix='test')\n","    epoch_end(model)\n","\n","  model = project_end(model)\n","  inference(data, model, test_type, prefix='train')\n","  inference(data, model, test_type, prefix='val')\n","  inference(data, model, test_type, prefix='test')\n","  return model\n","\n","def epoch_end(model):\n","\n","  val_list = total_loss_collect['val-mse']\n","  if len(val_list) > 1:\n","    if min(val_list) != val_list[-1]:\n","      pass\n","    else:\n","      torch.save(model.state_dict(), \"best_model.pt\")\n","\n","  else:\n","    torch.save(model.state_dict(), \"best_model.pt\")\n","\n","def project_end(model):\n","  model.load_state_dict(torch.load(\"best_model.pt\"))\n","  return model\n","\n","\n","def train_mask_fn(data, model, opt, test_type=[0,1,2]):\n","  model.train()\n","  train_mask_ = data.train_mask\n","  label = data.y\n","  pred = model(data)\n","\n","  loss = loss_fn(pred, label[:,test_type], train_mask_)\n","  score= score_fn(pred, label[:,test_type], train_mask_, prefix='train')\n","\n","  total_loss_collect['train'].append(loss.item())\n","  opt.zero_grad()\n","  loss.backward()\n","  opt.step()\n","\n","\n","def inference(data, model, test_type=[0,1,2,3], prefix='val'):\n","  \n","  model.eval()\n","  mask = getattr(data, prefix+\"_mask\")\n","  label = data.y\n","  pred = model(data)\n","  loss = loss_fn(pred, label[:,test_type], mask)\n","  score= score_fn(pred, label[:,test_type], mask, prefix=prefix)\n","\n","  total_loss_collect[prefix].append(loss.item())"],"metadata":{"id":"553RiXSxh-q8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mylog = HugeLog(fpath=\"log3.md\")\n","mylog.write(\"Data Description: \"+\"\\n All is TopK5, Propobability method : A/A.sum(-1)\")\n","mylog.write(\"All mask will be used!\")\n","\n","\n","graph1 = mydata.single_graph(\"/content/drive/MyDrive/deconvo_benchmark/data/Lung5_Rep1/new/spot_gene_expression.csv\",\n","                             \"/content/drive/MyDrive/deconvo_benchmark/data/Lung5_Rep1/new/ground_truth.csv\", topk=5)\n","\n","graph2 = mydata.single_graph(\"/content/drive/MyDrive/deconvo_benchmark/data/Lung5_Rep2/new/spot_gene_expression.csv\",\n","                             \"/content/drive/MyDrive/deconvo_benchmark/data/Lung5_Rep2/new/ground_truth.csv\",topk=5)\n","\n","graph3 = mydata.single_graph(\"/content/drive/MyDrive/deconvo_benchmark/data/Lung5_Rep3/new/spot_gene_expression.csv\",\n","                             \"/content/drive/MyDrive/deconvo_benchmark/data/Lung5_Rep3/new/ground_truth.csv\",topk=5)\n","\n","graph4 = mydata.single_graph(\"/content/drive/MyDrive/deconvo_benchmark/data/Lung12/new/spot_gene_expression.csv\",\n","                            \"/content/drive/MyDrive/deconvo_benchmark/data/Lung12/new/ground_truth.csv\",topk=5)\n","\n","graph5 = mydata.single_graph(\"/content/drive/MyDrive/deconvo_benchmark/data/Lung13/new/spot_gene_expression.csv\",\n","                            \"/content/drive/MyDrive/deconvo_benchmark/data/Lung13/new/ground_truth.csv\",topk=5)\n","\n","# total_graph = mydata.union_graph([graph1, graph2, graph3, graph4],topk=5)\n","total_graph = mydata.union_graph([graph1, graph2, graph3],topk=10)\n","\n","# test_mask, train_mask, val_mask = mydata.mask_graph(total_graph, masked_graph_idx=masked_graph_idx)\n","\n","lrs = [0.01,0.05,0.001,0.005]\n","# lrs = [0.01]\n","\n","weight_decay_list = [0.01, 0.05, 0.001, 0.005, 0.0001]\n","# weight_decay_list = [0.01]\n","\n","\n","# masked_jobs = [[2]]\n","masked_jobs = [[0], [1], [2]]\n","# masked_jobs = [[3]]\n","\n","for lr in lrs:\n","  for masked_graph_idx in masked_jobs:\n","\n","    test_mask, train_mask, val_mask = mydata.mask_graph(total_graph, masked_graph_idx=masked_graph_idx)\n","\n","    data = pyg_data_maker(total_graph.X, \n","                          total_graph.label, \n","                          total_graph.adj_link.T,\n","                          total_graph.adj_weight,\n","                          train_mask,\n","                          val_mask,\n","                          test_mask,\n","                          x_preprocess=False)\n","    \n","    mask_description = \"mask-{}\".format(\"-\".join(str(i) for i in masked_graph_idx))\n","\n","    # job1 \n","\n","    for weight_decay in weight_decay_list:\n","      test_type = list(range(18))\n","      total_loss_collect = defaultdict(list) \n","\n","      model = test_with_masked_type(test_type=test_type)\n","\n","      prefix = \"{}-{}-lr-{}-weight-decay-{}\".format(mask_description,len(test_type), lr, weight_decay)\n","      mylog.write(\"# \"+ prefix)\n","      saveResult(prefix)\n","      savefig(prefix)\n","      logrecord()\n","      outputSave(prefix, data=data)\n","\n","    # # job2 \n","    # for weight_decay in weight_decay_list:\n","    #   test_type = list(range(1,18))\n","    #   total_loss_collect = defaultdict(list) \n","\n","    #   model = test_with_masked_type(test_type=test_type)\n","\n","    #   prefix = \"{}-{}-lr-{}-weight-decay-{}\".format(mask_description,len(test_type), lr, weight_decay)\n","    #   mylog.write(\"# \"+ prefix)\n","    #   saveResult(prefix)\n","    #   savefig(prefix)\n","    #   logrecord()\n","    #   outputSave(prefix, data=data)\n","\n","m = open(\"log3.md\",'r').read().split('\\n')\n","content = defaultdict(list)\n","prefix = None\n","flag = True\n","columns = []\n","for idx in range(len(m)):\n","  if len(m[idx]) > 1:\n","    if m[idx][0] == \"#\":\n","      if prefix and flag:\n","        flag = False\n","      prefix = m[idx][2:]\n","      if \"log2\" in prefix:\n","        prefix = prefix[5:]\n","    elif prefix :\n","      if flag:\n","        columns.append(m[idx].split(\":\")[0])\n","      content[prefix].append(m[idx].split(\":\")[1])\n","klist = list(content.keys())\n","for i in klist:\n","  content[i] = content[i][:26]\n","df = pd.DataFrame(content).T\n","df.columns = columns\n","df.to_excel(\"res2.xlsx\")"],"metadata":{"id":"avosIvBzguDH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["os.mkdir(\"result\") \n","!mv *.csv result\n","!mv *.xlsx result\n","!mv log3.md result"],"metadata":{"id":"Eg6asNbe383p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mv result lung_123_5_10\n","!cp -r ./lung_123_5_10 /content/drive/MyDrive/CosMx_benchmark_pro/overall_result/lung/"],"metadata":{"id":"NixaHWrlQ-4e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"-87ZSf4eQ-8H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"7Ef0epQEQ-_A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"EPduP8Gytfz4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"AcB4KBfftf3G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Nj0Y46y3tf6Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"vo_sIDHGtf9Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Ikmfzm6TtgAP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"FediEt-CtgDI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"cIgfsvDUtgF_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Jrhl5RWutgJH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# m = open(\"log3.md\",'r').read().split('\\n')\n","# content = defaultdict(list)\n","# prefix = None\n","# flag = True\n","# columns = []\n","# for idx in range(len(m)):\n","#   if len(m[idx]) > 1:\n","#     if m[idx][0] == \"#\":\n","#       if prefix and flag:\n","#         flag = False\n","#       prefix = m[idx][2:]\n","#       if \"log2\" in prefix:\n","#         prefix = prefix[5:]\n","#     elif prefix :\n","#       if flag:\n","#         columns.append(m[idx].split(\":\")[0])\n","#       content[prefix].append(m[idx].split(\":\")[1])\n","\n","# df = pd.DataFrame(content).T\n","# df.columns = columns\n","# df.to_excel(\"res2.xlsx\")"],"metadata":{"id":"RrsIitD5hBky"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# def outputSave(prefix=None, data=None):\n","#   columns = \"tumor\tfibroblast\tmacrophage\tT CD4 memory\tT CD8 memory\tplasmablast\tB-cell\tmast\tTreg\tendothelial\tpDC\tT CD4 naive\tneutrophil\tT CD8 naive\tNK\tmonocyte\tepithelial\tmDC\".split(\"\t\")\n","#   data = F.softmax(model(data),dim=1).detach().cpu().numpy()\n","#   columns = columns[-1 * data.shape[-1]:]\n","#   split_idx = [0,600,1200, 1800,len(data.y)]\n","#   for idx in range(len(split_idx)-1):\n","#     df = pd.DataFrame(data[split_idx[idx] : split_idx[idx+1]], columns=columns)\n","#     df.to_csv(prefix+\"-predict-{}.csv\".format(idx))"],"metadata":{"id":"MCSrJIKr1YHE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# graph1 = mydata.single_graph(\"/content/drive/MyDrive/deconvo_benchmark/data/Lung5_Rep1/new/spot_gene_expression.csv\",\n","#                              \"/content/drive/MyDrive/deconvo_benchmark/data/Lung5_Rep1/new/ground_truth.csv\", topk=5)\n","# graph2 = mydata.single_graph(\"/content/drive/MyDrive/deconvo_benchmark/data/Lung5_Rep2/new/spot_gene_expression.csv\",\n","#                              \"/content/drive/MyDrive/deconvo_benchmark/data/Lung5_Rep2/new/ground_truth.csv\",topk=5)\n","# graph3 = mydata.single_graph(\"/content/drive/MyDrive/deconvo_benchmark/data/Lung5_Rep3/new/spot_gene_expression.csv\",\n","#                              \"/content/drive/MyDrive/deconvo_benchmark/data/Lung5_Rep3/new/ground_truth.csv\",topk=5)\n","\n","# graph4 = mydata.single_graph(\"/content/drive/MyDrive/deconvo_benchmark/data/Lung12/new/spot_gene_expression.csv\",\n","#                             \"/content/drive/MyDrive/deconvo_benchmark/data/Lung12/new/ground_truth.csv\",topk=5)\n","\n","# graph5 = mydata.single_graph(\"/content/drive/MyDrive/deconvo_benchmark/data/Lung13/new/spot_gene_expression.csv\",\n","#                             \"/content/drive/MyDrive/deconvo_benchmark/data/Lung13/new/ground_truth.csv\",topk=5)\n","# total_graph = mydata.union_graph([graph1, graph2, graph3, graph4],topk=5)\n","\n","# test_mask, train_mask, val_mask = mydata.mask_graph(total_graph, masked_graph_idx=[3])\n","# data = pyg_data_maker(total_graph.X, \n","#                         total_graph.label, \n","#                         total_graph.adj_link.T,\n","#                         total_graph.adj_weight,\n","#                         train_mask,\n","#                         val_mask,\n","#                         test_mask,\n","#                         x_preprocess=False)\n","# split_idx = [0,600,1200, 1800,len(data.y)]\n","# data.y = data.y.numpy()\n","# columns = \"tumor\tfibroblast\tmacrophage\tT CD4 memory\tT CD8 memory\tplasmablast\tB-cell\tmast\tTreg\tendothelial\tpDC\tT CD4 naive\tneutrophil\tT CD8 naive\tNK\tmonocyte\tepithelial\tmDC\".split(\"\t\")\n","# for idx in range(len(split_idx)-1):\n","#   df = pd.DataFrame(data.y[split_idx[idx] : split_idx[idx+1]], columns=columns)\n","#   df.to_csv(\"./ground-truth-prob-{}.csv\".format(idx))"],"metadata":{"id":"2-W25mAfyWQ9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"AQMJoCOgp56S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"K-aPuESOxXF_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"VPcN8JwOxbXy","executionInfo":{"status":"ok","timestamp":1684126784114,"user_tz":420,"elapsed":220,"user":{"displayName":"jiayuan ding","userId":"00368278201421210170"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"2_nYBnUizcOK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"jivcQHXPzcLi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"tjk3xmfhxdqn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"i4OH-U1az3T1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"zp-BR2L34bwl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"99V6_W4-4f9V"},"execution_count":null,"outputs":[]}]}